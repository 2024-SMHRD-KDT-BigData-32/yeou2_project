from fastapi import FastAPI, Request, HTTPException # FastAPI ì‚¬ìš©, API ì—ëŸ¬ ì²´í¬ 
from fastapi.middleware.cors import CORSMiddleware # Cross-Origin Resource Sharing ì„¤ì • 
from pydantic import BaseModel # JSON ë°ì´í„°ì˜ ìœ íš¨ì„± ê²€ì‚¬ ë° ìë™ ë³€í™˜
from dotenv import load_dotenv # .env íŒŒì¼ì— ì €ì¥ëœ í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©
from collections import defaultdict # Pythonì˜ ë”•ì…”ë„ˆë¦¬ í™•ì¥
import pymysql #Python, MySQL ì—°ê²° ë° ì¿¼ë¦¬ì‹¤í–‰
from openai import OpenAI
from collections import defaultdict
from contextlib import closing
from typing import List
import asyncio
import json
import numpy as np
import pandas as pd
import os
import faiss


# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ë° OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# FastAPI ì´ˆê¸°í™”
app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# DB ì—°ê²° í•¨ìˆ˜
def get_connection():
    return pymysql.connect(
        host='project-db-campus.smhrd.com',
        port=3307,
        user='campus_24K_BigData32_p2_3',
        password='smhrd3',
        db='campus_24K_BigData32_p2_3',
        charset='utf8mb4',
        cursorclass=pymysql.cursors.DictCursor
    )

# ê¸°ë³¸ ë£¨íŠ¸
@app.get("/")
def root():
    return {"message": "FastAPI ì„œë²„ ë™ì‘ ì¤‘!"}


@app.post("/searchGeneral")
async def search_simple(request: Request):
    data = await request.json()
    user_input = data.get("text", "")

    # ê³µë°±ìœ¼ë¡œ ë‚˜ëˆ ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords = [kw.strip() for kw in user_input.split() if kw.strip()]
    if not keywords:
        return {"original": user_input, "prod_idx_list": []}

    # WHERE ì ˆ ë§Œë“¤ê¸°
    where_clause = " OR ".join(["prod_name LIKE %s OR prod_performance LIKE %s" for _ in keywords])
    params = [f"%{kw}%" for kw in keywords for _ in range(2)]

    sql = f"""
        SELECT prod_idx, prod_category
        FROM tb_product
        WHERE {where_clause}
        ORDER BY prod_category
    """

    try:
        conn = get_connection()
        cursor = conn.cursor()
        cursor.execute(sql, params)
        rows = cursor.fetchall()
        conn.close()
    except Exception as e:
        print("âŒ DB ì—ëŸ¬:", e)
        return {"original": user_input, "prod_idx_list": []}

    # ì¹´í…Œê³ ë¦¬ë³„ ìµœëŒ€ 10ê°œ
    category_map = defaultdict(list)
    for row in rows:
        cat = row["prod_category"]
        category_map[cat].append(row["prod_idx"])

    result_ids = [pid for ids in category_map.values() for pid in ids]
    return {
        "original": user_input,
        "prod_idx_list": result_ids
    }


# ìƒí’ˆ ì •ë³´ ì¡°íšŒ
@app.post("/getProductsByIds")
async def get_products_by_ids(payload: dict):
    ids = payload.get("ids", [])

    if not ids:
        return {"products": []}

    placeholders = ','.join(['%s'] * len(ids))

    sql = f"""
        SELECT 
            p.prod_idx,
            p.prod_name,
            p.prod_category,
            p.prod_performance,
            p.prod_img,
            MIN(pp.prod_price) AS prod_price
        FROM 
            tb_product p
        JOIN 
            tb_product_price pp ON p.prod_idx = pp.prod_idx
        WHERE 
            p.prod_idx IN ({placeholders})
        GROUP BY 
            p.prod_idx, p.prod_name, p.prod_category, p.prod_performance, p.prod_img
    """
    try:
        conn = get_connection()
        cursor = conn.cursor(pymysql.cursors.DictCursor)

        cursor.execute(sql, ids)
        # ì»¤ì„œë¡œ ì°ê¸°: ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì˜¨ ê²°ê³¼ë¥¼ ì§ì ‘ ì°ì–´ë´„
        rows = cursor.fetchall()
        cursor.close()
        conn.commit()
        conn.close()
        return {"products": rows}
    except Exception as e:
        print("âŒ DB ì—ëŸ¬:", e)
        return {"products": []}
    
#--------------------------------------------------------------
# ì´ ì ‘ì†ì ìˆ˜ ë‚˜íƒ€ë‚´ê¸°
VISIT_COUNT_FILE = 'main_home_visits.txt'

def get_visit_count():
    try:
        with open(VISIT_COUNT_FILE, 'r') as f:
            count = int(f.read())
    except FileNotFoundError:
        count = 0
    return count

def increment_visit_count():
    count = get_visit_count()
    count += 1
    with open(VISIT_COUNT_FILE, 'w') as f:
        f.write(str(count))

@app.post('/main-home-visit')
async def record_visit():
    increment_visit_count()
    return {"message": "Main homepage visit recorded successfully"}

# 2. ë°©ë¬¸ íšŸìˆ˜ ì¡°íšŒ (GET `/api/main-home-visits`):
@app.get('/main-home-visits')
async def get_visits():
    count = get_visit_count()
    return {"count": count}



#ìƒí’ˆì¡°íšŒ
@app.get("/getProducts")
async def get_products():
    sql = """
        SELECT 
            p.prod_idx AS id,
            p.prod_name AS productName,
            MIN(pp.prod_price) AS productPrice 
            FROM 
                tb_product p 
            JOIN
                tb_product_price pp ON p.prod_idx = pp.prod_idx
            Group by p.prod_idx

    """

    try:
        conn = get_connection()
        cursor = conn.cursor(pymysql.cursors.DictCursor)
        cursor.execute(sql)
        rows = cursor.fetchall()
        conn.close()
        return {"products": rows}  
    except Exception as e:
        print("âŒ DB ì—ëŸ¬:", e)
        raise HTTPException(status_code=500, detail="Database error")
    

@app.get("/getProductPrices/{prod_idx}")
async def get_product_prices(prod_idx: int):
    sql = """
        SELECT prod_price, prod_shoppingmall, prod_link 
        FROM tb_product_price 
        WHERE prod_idx = %s
        ORDER BY prod_price ASC
    """
    try:
        conn = get_connection()
        cursor = conn.cursor(pymysql.cursors.DictCursor)
        cursor.execute(sql, (prod_idx,))
        rows = cursor.fetchall()
        conn.close()
        return {"prices": rows}
    except Exception as e:
        print("âŒ ê°€ê²© ë°ì´í„° ì—ëŸ¬:", e)
        raise HTTPException(status_code=500, detail="ê°€ê²© ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
    

@app.post("/chat")
async def chat(request: Request):
    data = await request.json()
    user_message = data.get("message", "")

    # OpenAI ChatGPT í˜¸ì¶œ
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",  # ë˜ëŠ” "gpt-4"
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê³ ê° ì§€ì› ì±—ë´‡ì…ë‹ˆë‹¤."},
            {"role": "user", "content": user_message}
        ]
    )

    reply = response.choices[0].message.content.strip()

    return {"reply": reply}

@app.get("/getMembers")
async def get_members():
    # DB ì—°ê²° ë° ì¿¼ë¦¬ ì‹¤í–‰
    sql = """
        SELECT mb_name, mb_nick, mb_email, mb_gender, mb_birthdate, mb_role, joined_at, mb_id
        FROM tb_member
    """
    try:
        conn = get_connection()
        cursor = conn.cursor(pymysql.cursors.DictCursor)
        cursor.execute(sql)
        rows = cursor.fetchall()
        conn.close()
        
        # ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
        return {"members": rows}
    except Exception as e:
        print("âŒ DB ì—ëŸ¬:", e)
        raise HTTPException(status_code=500, detail="Database error")
    


@app.post("/change-role")
async def change_role(data: dict):
    mb_id = data.get("mb_id")
    new_role = data.get("new_role", "ADMIN")

    try:
        conn = get_connection()
        cur = conn.cursor()
        cur.execute("UPDATE tb_member SET mb_role = %s WHERE mb_id = %s", (new_role, mb_id))
        conn.commit()
        return {"success": True}
    except Exception as e:
        print("Error updating role:", e)
        return {"success": False}
    

# # DB í…ŒìŠ¤íŠ¸ìš© ì—”ë“œí¬ì¸íŠ¸
# @app.get("/test-db")
# def test_db_connection():
#     try:
#         conn = get_connection()
#         with conn.cursor() as cursor:
#             cursor.execute("SELECT NOW() AS now_time;")
#             result = cursor.fetchone()
#         return {"status": "success", "db_time": str(result["now_time"])}
#     except Exception as e:
#         return {
#             "status": "fail",
#             "error": str(e),
#         }


# ì‚¬ìš©ì ê²€ìƒ‰ì–´ tb_search ì €ì¥
def insert_search_text(conn, mb_id, search_text):
    with conn.cursor() as cursor:
        sql = """
            INSERT INTO tb_search (mb_id, search_text, created_at)
            VALUES (%s, %s, NOW())
        """
        print("ğŸŸ¡ INSERT ì‹¤í–‰ ì „:", mb_id, search_text)
        cursor.execute(sql, (mb_id, search_text))
        print("âœ… ê²€ìƒ‰ì–´ ì €ì¥ ì™„ë£Œ:", mb_id, search_text)
    conn.commit()
    print("ğŸŸ¢ INSERT ì™„ë£Œ")  # ì¶”ê°€


# í…ìŠ¤íŠ¸ ì„ë² ë”©
# ì‚¬ìš©ì ê²€ìƒ‰ì–´ë¥¼ ë²¡í„°í™”í•˜ì—¬ numpy ë°°ì—´ë¡œ ë³€í™˜
def embed_text(text):
    response = client.embeddings.create(
        model="text-embedding-ada-002",
        input=text
    )
    return np.array(response.data[0].embedding, dtype="float32")


# ì„ë² ë”© í…Œì´ë¸” ë¡œë“œ
# tb_embedding í…Œì´ë¸”ì—ì„œ source_type = 'product'ì¸ ë²¡í„°ë“¤ ë¡œë“œ
def load_product_embeddings(conn):
    with conn.cursor() as cursor:
        cursor.execute("SELECT embedding_id, source_id, embedding_text FROM tb_embedding WHERE source_type = 'product'")
        rows = cursor.fetchall()

    ids, metadata, vectors = [], [], []
    for row in rows:
        ids.append(row['embedding_id'])
        metadata.append(row['source_id'])
        vectors.append(json.loads(row['embedding_text']))

    return ids, metadata, np.array(vectors, dtype='float32')


# FAISS ìœ ì‚¬ë„ ê²€ìƒ‰
# FAISSë¥¼ ì‚¬ìš©í•´ ë²¡í„° ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ TOP 100 ID ì¶”ì¶œ
def find_top_n_similar(query_vec, vectors, metadata, top_n=100):
    dim = vectors.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(vectors)
    _, I = index.search(np.array([query_vec]), top_n)
    return [metadata[i] for i in I[0]]


# ì œí’ˆ ì •ë³´ ì¡°íšŒ
# ì¶”ì²œëœ product_ids ê¸°ì¤€ìœ¼ë¡œ tb_product, tb_product_price, tb_reviewë¥¼ ì¡°ì¸í•˜ì—¬ ìƒì„¸ ì •ë³´ ì¡°íšŒ
def fetch_product_info(conn, product_ids):
    if not product_ids:
        return []

    with conn.cursor() as cursor:
        format_strings = ','.join(['%s'] * len(product_ids))
        sql = f"""
            SELECT 
                p.prod_idx, 
                p.prod_name, 
                p.prod_category,
                p.prod_img,
                pp.prod_price,
                pp.prod_shoppingmall,
                pp.prod_link,
                r.review_text
            FROM tb_product p
            LEFT JOIN tb_product_price pp ON p.prod_idx = pp.prod_idx
            LEFT JOIN tb_review r ON p.prod_idx = r.prod_idx
            WHERE p.prod_idx IN ({format_strings})
        """
        cursor.execute(sql, tuple(product_ids))
        return cursor.fetchall()


# ì¶”ì²œ ë¡œì§
def recommend_products_by_search(mb_id, search_text):
    conn = get_connection()
    try:
        print("ğŸ”µ ê²€ìƒ‰ì–´ ì €ì¥ ì‹œë„:", mb_id, search_text)
        insert_search_text(conn, mb_id, search_text)
        query_vector = embed_text(search_text)
        ids, metadata, vectors = load_product_embeddings(conn)
        top_ids = find_top_n_similar(query_vector, vectors, metadata)
        products = fetch_product_info(conn, top_ids)

        category_dict = defaultdict(list)
        for item in products:
            category_dict[item['prod_category']].append(item)

        top5_by_category = []
        for category, items in category_dict.items():
            top5_by_category.extend(items[:5])

        return top5_by_category
    
    except Exception as e:
        print("âŒ ê²€ìƒ‰ì–´ ì €ì¥ ì‹¤íŒ¨:", e)

    finally:
        conn.close()


# ìš”ì²­ ëª¨ë¸ ì •ì˜
class SearchRequest(BaseModel):
    mb_id: str
    query: str


# ìµœì¢… ì¶”ì²œ API
# ì¶”ì²œ ê²°ê³¼ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜
# í”„ë¡ íŠ¸ì—ì„œ Object.entries()ë¡œ ë°˜ë³µ ë Œë”ë§ ê°€ëŠ¥
@app.post("/ai-search")
def ai_search(data: SearchRequest):
    try:
        recommendations = recommend_products_by_search(data.mb_id, data.query)

        result_by_category = defaultdict(list)
        for item in recommendations:
            result_by_category[item["prod_category"]].append(item)

        return result_by_category
    except Exception as e:
        print("âŒ AI ì¶”ì²œ ì²˜ë¦¬ ì‹¤íŒ¨:", e)
        raise HTTPException(status_code=500, detail=str(e))
